{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIjIxfjUx1pF"
   },
   "source": [
    "## *Nagłówek sprawozdania*\n",
    "\n",
    "*kto, kiedy, na jakich zajęciach, itp., itd. - do uzypełnienia!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZln09l59xoe"
   },
   "source": [
    "# Analiza obrazu - detekcja twarzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcp9Z1Bb4LbJ"
   },
   "source": [
    "Do realizacji zadań wykorzystywane są biblioteki OpenCV, dlib oraz InsightFace (wymaga dodatkowo pakietu onnxruntime), ponadto wykorzystywana jest biblioteka PIL/pillow do wyświetlania obrazów w notatniku. Biblioteki te muszą być zainstalowane w środowisku Python, odpowiedni plik <tt>requirements.txt</tt> został udostępniony razem z notatnikiem.\n",
    "\n",
    "Do wykonania notatnika potrzebne są:\n",
    "- obraz testowy: <tt>2_Demonstration_Demonstration_Or_Protest_2_58.jpg</tt>\n",
    "- model detektora Haar: <tt>haarcascade_frontalface_default.xml</tt>\n",
    "- model detektora MMOD (sieć neuronowa z biblioteki dlib): <tt>mmod_human_face_detector.dat</tt>\n",
    "- modele detektora twarzy (siec neuronowa) z biblioteki insightface: katalog <tt>insightface</tt>\n",
    "\n",
    "Wszystkie potrzebne pliki powinny znajdować się w tym samym katalogu co notatnik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pracując w środowisku Google Colab należy potrzebne pliki wejściowe wgrać do środowiska notatnika - można to zrobić za pomocą interfejsu środowiska w przeglądarce, lub za pomocą widgetu 'upload'. Alternatywnie można wczytywać dane z własnego dysku Google Drive, co może być czasami przydatne - wgrywanie plików do środowiska Colab może być czasochłonne (w przypadku dużej liczby plików lub dużego ich rozmiaru), ponadto jest wymagane każdorazowo po inicjalizacji środowiska (przykłady poniżej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # alternatywnie - czytanie plików z dysku Google Drive, w tym celu należy zamontować dysk:\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# # i ustawić właściwą ścieżkę do danych w zmiennej, np.:\n",
    "# data_dir = \"/content/drive/My Drive/Colab Notebooks/...../\"\n",
    "# # konieczna będzie również modyfikacja dalszych fragmentów kodu, aby uwzględnić inną lokalizację plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5MZZR3fB8Ke"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "# # w środowisku Colab biblioteka insightface wymaga zainstalowania\n",
    "# !pip install insightface\n",
    "# !pip install onnxruntime\n",
    "import insightface \n",
    "\n",
    "# from google.colab.patches import cv2_imshow  # tylko w środowisku Colab\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGxinETn5K15"
   },
   "source": [
    "## Obraz testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4u9aVxFOF_aZ"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"2_Demonstration_Demonstration_Or_Protest_2_58.jpg\")\n",
    "# przygotowanie obrazów: monochromatycznego i RGB (cv2.imread() zwraca obraz w formacie BGR - inna kolejność składowych)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# cv2_imshow(img)  # tylko w środowisku Colab\n",
    "display(Image.fromarray(img_rgb))  # display() wymaga obrazu RGB (w przeciwieństwie do cv2.imshow(), która wymaga BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OttR_7b_IKS7"
   },
   "source": [
    "## Kaskada Haara\n",
    "\n",
    "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/05/opencv-face-detection-with-haar-cascades/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzJr4nUVCE_c"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "haar_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uQ2T_C5GH7S"
   },
   "outputs": [],
   "source": [
    "# wywołanie detektora dla określonego obrazu (img_gray)\n",
    "# wynikiem jest lista prostokątów w formacie [x, y, width, height]\n",
    "haar_results = haar_detector.detectMultiScale(img_gray, scaleFactor=1.05, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "print(len(haar_results))\n",
    "\n",
    "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "img_haar = img_rgb.copy()\n",
    "for (x, y, w, h) in haar_results:\n",
    "  cv2.rectangle(img_haar, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "display(Image.fromarray(img_haar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdWKPv1RIFkE"
   },
   "source": [
    "## Histogram zorientowanych gradientów (HOG) z maszyną wektorów nośnych (SVM)\n",
    "\n",
    "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/19/face-detection-with-dlib-hog-and-cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eC4Tf9PnIRTj"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "hog_svm_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEhDJvWYOmXO"
   },
   "outputs": [],
   "source": [
    "# wywołanie detektora dla określonego obrazu (img_rgb)\n",
    "# wynikiem jest lista obiektów rectangle, zawierających współrzędne lewego górnego i prawego dolnego narożnika prostokąta\n",
    "hog_svm_results = hog_svm_detector(img_rgb, 1)\n",
    "print(len(hog_svm_results))\n",
    "\n",
    "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "img_hog_svm = img_rgb.copy()\n",
    "for rect in hog_svm_results:\n",
    "\tcv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "display(Image.fromarray(img_hog_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-05vni26Px5J"
   },
   "source": [
    "## Splotowa sieć neuronowa (CNN) z biblioteki dlib\n",
    "\n",
    "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/19/face-detection-with-dlib-hog-and-cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSmzL4FxPLaA"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "cnn1_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgPDzLrAStOF"
   },
   "outputs": [],
   "source": [
    "# wywołanie detektora dla określonego obrazu (img_rgb)\n",
    "# wynikiem jest lista obiektów mmod_rectangle, zawierających m.in. pole rect ze współrzędnymi lewego górnego i prawego dolnego narożnika prostokąta\n",
    "cnn1_results = cnn1_detector(img_rgb, 1)\n",
    "print(len(cnn1_results))\n",
    "\n",
    "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "img_cnn1 = img_rgb.copy()\n",
    "for res in cnn1_results:\n",
    "\trect = res.rect\n",
    "\tcv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "display(Image.fromarray(img_cnn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghePuqG7IsXY"
   },
   "source": [
    "## InsightFace - inna sieć neuronowa\n",
    "\n",
    "Opracowano na podstawie: https://github.com/deepinsight/insightface/tree/master/python-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u0pZhLPDqXuP"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "model_name = 'buffalo_s'  # model: small (_s), medium (_m) lub large (_l)\n",
    "insf_detector = insightface.app.FaceAnalysis(name=model_name, root='insightface',\n",
    "                                             allowed_modules=['detection'], providers=['CPUExecutionProvider'])\n",
    "insf_detector.prepare(ctx_id=0, det_size=(1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1czShMPI8FZ"
   },
   "outputs": [],
   "source": [
    "# wywołanie detektora dla określonego obrazu\n",
    "# wynikiem jest lista obiektów, zawierających m.in. pole bbox ze współrzędnymi lewego górnego i prawego dolnego narożnika prostokąta\n",
    "insf_results = insf_detector.get(img)\n",
    "print(len(insf_results))\n",
    "\n",
    "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "img_insf = img_rgb.copy()\n",
    "for res in insf_results:\n",
    "  # współrzędne prostokątów sa zapisane jako liczby rzeczywiste - konwersja do liczb całkowitych\n",
    "  rect = res.bbox.round().astype(int)\n",
    "  cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "display(Image.fromarray(img_insf))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
