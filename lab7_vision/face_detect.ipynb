{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIjIxfjUx1pF"
   },
   "source": [
    "## LABORATORIUM NR. 7\n",
    "\n",
    "Łukasz Szydlik 331446 - 05.05.2025 - Lab. WMM gr. 101 Poniedziałek 16:15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZln09l59xoe"
   },
   "source": [
    "# Analiza obrazu - detekcja twarzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcp9Z1Bb4LbJ"
   },
   "source": [
    "Do realizacji zadań wykorzystywane są biblioteki OpenCV, dlib oraz InsightFace (wymaga dodatkowo pakietu onnxruntime), ponadto wykorzystywana jest biblioteka PIL/pillow do wyświetlania obrazów w notatniku. Biblioteki te muszą być zainstalowane w środowisku Python, odpowiedni plik <tt>requirements.txt</tt> został udostępniony razem z notatnikiem.\n",
    "\n",
    "Do wykonania notatnika potrzebne są:\n",
    "- obraz testowy: <tt>2_Demonstration_Demonstration_Or_Protest_2_58.jpg</tt>\n",
    "- model detektora Haar: <tt>haarcascade_frontalface_default.xml</tt>\n",
    "- model detektora MMOD (sieć neuronowa z biblioteki dlib): <tt>mmod_human_face_detector.dat</tt>\n",
    "- modele detektora twarzy (siec neuronowa) z biblioteki insightface: katalog <tt>insightface</tt>\n",
    "\n",
    "Wszystkie potrzebne pliki powinny znajdować się w tym samym katalogu co notatnik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pracując w środowisku Google Colab należy potrzebne pliki wejściowe wgrać do środowiska notatnika - można to zrobić za pomocą interfejsu środowiska w przeglądarce, lub za pomocą widgetu 'upload'. Alternatywnie można wczytywać dane z własnego dysku Google Drive, co może być czasami przydatne - wgrywanie plików do środowiska Colab może być czasochłonne (w przypadku dużej liczby plików lub dużego ich rozmiaru), ponadto jest wymagane każdorazowo po inicjalizacji środowiska (przykłady poniżej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # alternatywnie - czytanie plików z dysku Google Drive, w tym celu należy zamontować dysk:\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\", force_remount=True)\n",
    "# # i ustawić właściwą ścieżkę do danych w zmiennej, np.:\n",
    "# data_dir = \"/content/drive/My Drive/Colab Notebooks/...../\"\n",
    "# # konieczna będzie również modyfikacja dalszych fragmentów kodu, aby uwzględnić inną lokalizację plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "W5MZZR3fB8Ke"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# # w środowisku Colab biblioteka insightface wymaga zainstalowania\n",
    "# !pip install insightface\n",
    "# !pip install onnxruntime\n",
    "import insightface\n",
    "\n",
    "# from google.colab.patches import cv2_imshow  # tylko w środowisku Colab\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "images_path = [\n",
    "    \"2_Demonstration_Demonstration_Or_Protest_2_58.jpg\",\n",
    "    \"4_Dancing_Dancing_4_489.jpg\",\n",
    "    \"30_Surgeons_Surgeons_30_256.jpg\",\n",
    "    \"50_Celebration_Or_Party_houseparty_50_17.jpg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_result(image, filename): # rgb img\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    cv2.imwrite(f\"results/{filename}.jpg\", cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGxinETn5K15"
   },
   "source": [
    "## Zadania 1-2. Detekcja twarzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "4u9aVxFOF_aZ"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "images_gray = []\n",
    "images_rgb = []\n",
    "\n",
    "for number, image_path in zip(range(0, len(images_path)), images_path):\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    # przygotowanie obrazów: monochromatycznego i RGB (cv2.imread() zwraca obraz w formacie BGR - inna kolejność składowych)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    images.append(img)\n",
    "    images_gray.append(img_gray)\n",
    "    images_rgb.append(img_rgb)\n",
    "\n",
    "    # cv2_imshow(img)  # tylko w środowisku Colab\n",
    "    # display(Image.fromarray(img_rgb))  # display() wymaga obrazu RGB (w przeciwieństwie do cv2.imshow(), która wymaga BGR)\n",
    "\n",
    "    save_result(img_rgb, f\"img{number+1}_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OttR_7b_IKS7"
   },
   "source": [
    "## Kaskada Haara\n",
    "\n",
    "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/05/opencv-face-detection-with-haar-cascades/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "VzJr4nUVCE_c"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "haar_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "0uQ2T_C5GH7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "31\n",
      "1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for number, image_path in zip(range(0, len(images_path)), images_path):\n",
    "    # wywołanie detektora dla określonego obrazu (img_gray)\n",
    "    # wynikiem jest lista prostokątów w formacie [x, y, width, height]\n",
    "    haar_results = haar_detector.detectMultiScale(images_gray[number], scaleFactor=1.05, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    print(len(haar_results))\n",
    "\n",
    "    # narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "    img_haar = images_rgb[number].copy()\n",
    "    for (x, y, w, h) in haar_results:\n",
    "        cv2.rectangle(img_haar, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_haar))\n",
    "    save_result(img_haar, f\"img{number+1}_Haar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdWKPv1RIFkE"
   },
   "source": [
    "## Histogram zorientowanych gradientów (HOG) z maszyną wektorów nośnych (SVM)\n",
    "\n",
    "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/19/face-detection-with-dlib-hog-and-cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "eC4Tf9PnIRTj"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "hog_svm_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEhDJvWYOmXO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "26\n",
      "0\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for number, image_path in zip(range(0, len(images_path)), images_path):\n",
    "\n",
    "    # wywołanie detektora dla określonego obrazu (images_rgb[number])\n",
    "    # wynikiem jest lista obiektów rectangle, zawierających współrzędne lewego górnego i prawego dolnego narożnika prostokąta\n",
    "    hog_svm_results = hog_svm_detector(images_rgb[number], 1)\n",
    "    print(len(hog_svm_results))\n",
    "\n",
    "    # narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "    img_hog_svm = images_rgb[number].copy()\n",
    "    for rect in hog_svm_results:\n",
    "        cv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_hog_svm))\n",
    "    save_result(img_hog_svm, f\"img{number+1}_HOG_SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-05vni26Px5J"
   },
   "source": [
    "## Splotowa sieć neuronowa (CNN) z biblioteki dlib\n",
    "\n",
    "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/19/face-detection-with-dlib-hog-and-cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "JSmzL4FxPLaA"
   },
   "outputs": [],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "cnn1_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgPDzLrAStOF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "26\n",
      "0\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for number, image_path in zip(range(0, len(images_path)), images_path):\n",
    "\n",
    "    # wywołanie detektora dla określonego obrazu (images_rgb[number])\n",
    "    # wynikiem jest lista obiektów mmod_rectangle, zawierających m.in. pole rect ze współrzędnymi lewego górnego i prawego dolnego narożnika prostokąta\n",
    "    cnn1_results = cnn1_detector(images_rgb[number], 1)\n",
    "    print(len(cnn1_results))\n",
    "\n",
    "    # narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "    img_cnn1 = images_rgb[number].copy()\n",
    "    for res in cnn1_results:\n",
    "        rect = res.rect\n",
    "        cv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_cnn1))\n",
    "    save_result(img_cnn1, f\"img{number+1}_CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghePuqG7IsXY"
   },
   "source": [
    "## InsightFace - inna sieć neuronowa\n",
    "\n",
    "Opracowano na podstawie: https://github.com/deepinsight/insightface/tree/master/python-package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "u0pZhLPDqXuP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: insightface\\models\\buffalo_s\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# utworzenie i inicjalizacja detektora\n",
    "model_name = 'buffalo_s'  # model: small (_s), medium (_m) lub large (_l)\n",
    "insf_detector = insightface.app.FaceAnalysis(name=model_name, root='insightface',\n",
    "                                             allowed_modules=['detection'], providers=['CPUExecutionProvider'])\n",
    "insf_detector.prepare(ctx_id=0, det_size=(1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1czShMPI8FZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "38\n",
      "3\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for number, image_path in zip(range(0, len(images_path)), images_path):\n",
    "\n",
    "    # wywołanie detektora dla określonego obrazu\n",
    "    # wynikiem jest lista obiektów, zawierających m.in. pole bbox ze współrzędnymi lewego górnego i prawego dolnego narożnika prostokąta\n",
    "    insf_results = insf_detector.get(images[number])\n",
    "    print(len(insf_results))\n",
    "\n",
    "    # narysowanie wyników na kopii obrazu i wyświetlenie\n",
    "    img_insf = images_rgb[number].copy()\n",
    "    for res in insf_results:\n",
    "    # współrzędne prostokątów sa zapisane jako liczby rzeczywiste - konwersja do liczb całkowitych\n",
    "        rect = res.bbox.round().astype(int)\n",
    "        cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_insf))\n",
    "    save_result(img_insf, f\"img{number+1}_InsightFace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funckja do wyznaczania miar jakości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def face_detection_summary(name_list, GT_list, TP_list, FP_list):\n",
    "    \"\"\"\n",
    "    Creates a combined DataFrame with face detection metrics for multiple detectors.\n",
    "\n",
    "    Parameters:\n",
    "    - name_list: list of detector names\n",
    "    - GT_list: list of Ground Truth counts\n",
    "    - TP_list: list of True Positives\n",
    "    - FP_list: list of False Positives\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame with 'Metric' as rows and each detector as a separate column\n",
    "    \"\"\"\n",
    "    all_data = {}\n",
    "\n",
    "    for name, GT, TP, FP in zip(name_list, GT_list, TP_list, FP_list):\n",
    "        FN = GT - TP\n",
    "        total_detections = TP + FP\n",
    "\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / GT if GT > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        miss_rate = FN / GT if GT > 0 else 0\n",
    "\n",
    "        all_data[name] = [\n",
    "            GT,\n",
    "            total_detections,\n",
    "            TP,\n",
    "            FN,\n",
    "            FP,\n",
    "            round(precision, 2),\n",
    "            round(recall, 2),\n",
    "            round(f1, 2),\n",
    "            round(miss_rate, 2),\n",
    "        ]\n",
    "\n",
    "    metrics_labels = [\n",
    "        'Ground Truth (GT)',\n",
    "        'Total Detections',\n",
    "        'True Positives (TP)',\n",
    "        'False Negatives (FN)',\n",
    "        'False Positives (FP)',\n",
    "        'Precision',\n",
    "        'Recall',\n",
    "        'F1-score',\n",
    "        'Miss Rate',\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(all_data, index=metrics_labels)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 - Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_Demonstration_Demonstration_Or_Protest_2_58\n",
      "                        Haar  HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)     104.00   104.00    104.00       104.00\n",
      "Total Detections       23.00    21.00     27.00        56.00\n",
      "True Positives (TP)    21.00    21.00     27.00        56.00\n",
      "False Negatives (FN)   83.00    83.00     77.00        48.00\n",
      "False Positives (FP)    2.00     0.00      0.00         0.00\n",
      "Precision               0.91     1.00      1.00         1.00\n",
      "Recall                  0.20     0.20      0.26         0.54\n",
      "F1-score                0.33     0.34      0.41         0.70\n",
      "Miss Rate               0.80     0.80      0.74         0.46\n"
     ]
    }
   ],
   "source": [
    "detectors_1 = {\n",
    "    \"name\": [\"Haar\", \"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [104, 104, 104, 104], # reference 101\n",
    "    \"TP\": [21, 21, 27, 56],\n",
    "    \"FP\": [2, 0, 0, 0],\n",
    "}\n",
    "\n",
    "df_combined_summary_1 = face_detection_summary(\n",
    "    name_list=detectors_1[\"name\"],\n",
    "    GT_list=detectors_1[\"GT\"],\n",
    "    TP_list=detectors_1[\"TP\"],\n",
    "    FP_list=detectors_1[\"FP\"]\n",
    ")\n",
    "\n",
    "print(\"2_Demonstration_Demonstration_Or_Protest_2_58\")\n",
    "print(df_combined_summary_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 - Porównanie wyników\n",
    "1. Haar detector (OpenCV)\n",
    "    - Bardzo niska czułość (recall 0.20) – wykrywa tylko niewielką część wszyskich twarzy.\n",
    "    - Precision (0.91) jest wysoka, ale duża liczba FN (83) pokazuje, że wiele twarzy zostało pominiętych.\n",
    "1. HOG + SVM (Dlib)\n",
    "    - Bardzo podobna skuteczność do detektora Haar – identyczna liczba TP i FN, ale brak FP (Precision = 1.00).\n",
    "    - Nadal bardzo niska skuteczność detekcji – Recall = 0.20.\n",
    "1. CNN MMOD (Dlib)\n",
    "    - Nieco lepsze pokrycie niż poprzednie (Recall = 0.26), bez fałszywych pozytywów.\n",
    "    - Zmniejszenie Miss Rate do 0.74 oznacza poprawę, ale wciąż większość twarzy jest pomijana.\n",
    "1. CNN InsightFace\n",
    "    - Najlepsze wyniki ze wszystkich detektorów:\n",
    "    - Recall = 0.54 – wykryto ponad połowę twarzy,\n",
    "    - Precision = 1.00 – zero błędnych detekcji,\n",
    "    - F1-score = 0.70 – zbalansowana miara skuteczności.\n",
    "    - Wciąż pominięto 48 twarzy, ale to i tak znacznie lepiej niż konkurencja.\n",
    "\n",
    "- Precision we wszystkich detektorach jest wysoka lub idealna (1.00) – oznacza to, że mało jest błędnych detekcji.\n",
    "- Problemem jest recall – czyli wykrywanie wszystkich rzeczywistych twarzy.\n",
    "- Żaden z modeli nie radzi sobie z wykrywaniem twarzy od tyłu i mocno pochylonych w dół."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 - Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_Dancing_Dancing_4_489\n",
      "                       Haar  HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)     39.00    39.00     39.00        39.00\n",
      "Total Detections      31.00    26.00     26.00        38.00\n",
      "True Positives (TP)   26.00    26.00     26.00        37.00\n",
      "False Negatives (FN)  13.00    13.00     13.00         2.00\n",
      "False Positives (FP)   5.00     0.00      0.00         1.00\n",
      "Precision              0.84     1.00      1.00         0.97\n",
      "Recall                 0.67     0.67      0.67         0.95\n",
      "F1-score               0.74     0.80      0.80         0.96\n",
      "Miss Rate              0.33     0.33      0.33         0.05\n",
      "\n",
      "30_Surgeons_Surgeons_30_256\n",
      "                      Haar  HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)      5.0      5.0       5.0         5.00\n",
      "Total Detections       1.0      0.0       0.0         3.00\n",
      "True Positives (TP)    0.0      0.0       0.0         3.00\n",
      "False Negatives (FN)   5.0      5.0       5.0         2.00\n",
      "False Positives (FP)   1.0      0.0       0.0         0.00\n",
      "Precision              0.0      0.0       0.0         1.00\n",
      "Recall                 0.0      0.0       0.0         0.60\n",
      "F1-score               0.0      0.0       0.0         0.75\n",
      "Miss Rate              1.0      1.0       1.0         0.40\n",
      "\n",
      "50_Celebration_Or_Party_houseparty_50_17\n",
      "                       Haar  HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)     11.00    11.00      11.0         11.0\n",
      "Total Detections      10.00     6.00      11.0         11.0\n",
      "True Positives (TP)    6.00     6.00      11.0         11.0\n",
      "False Negatives (FN)   5.00     5.00       0.0          0.0\n",
      "False Positives (FP)   4.00     0.00       0.0          0.0\n",
      "Precision              0.60     1.00       1.0          1.0\n",
      "Recall                 0.55     0.55       1.0          1.0\n",
      "F1-score               0.57     0.71       1.0          1.0\n",
      "Miss Rate              0.45     0.45       0.0          0.0\n"
     ]
    }
   ],
   "source": [
    "# 4_Dancing_Dancing_4_489\n",
    "detectors_2 = {\n",
    "    \"name\": [\"Haar\", \"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [39, 39, 39, 39], # reference 39\n",
    "    \"TP\": [26, 26, 26, 37],\n",
    "    \"FP\": [5, 0, 0, 1],\n",
    "}\n",
    "\n",
    "df_combined_summary_2 = face_detection_summary(\n",
    "    name_list=detectors_2[\"name\"],\n",
    "    GT_list=detectors_2[\"GT\"],\n",
    "    TP_list=detectors_2[\"TP\"],\n",
    "    FP_list=detectors_2[\"FP\"]\n",
    ")\n",
    "\n",
    "# 30_Surgeons_Surgeons_30_256\n",
    "detectors_3 = {\n",
    "    \"name\": [\"Haar\", \"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [5, 5, 5, 5], # reference 101\n",
    "    \"TP\": [0, 0, 0, 3],\n",
    "    \"FP\": [1, 0, 0, 0],\n",
    "}\n",
    "\n",
    "df_combined_summary_3 = face_detection_summary(\n",
    "    name_list=detectors_3[\"name\"],\n",
    "    GT_list=detectors_3[\"GT\"],\n",
    "    TP_list=detectors_3[\"TP\"],\n",
    "    FP_list=detectors_3[\"FP\"]\n",
    ")\n",
    "\n",
    "# 50_Celebration_Or_Party_houseparty_50_17\n",
    "detectors_4 = {\n",
    "    \"name\": [\"Haar\", \"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [11, 11, 11, 11], # reference 11\n",
    "    \"TP\": [6, 6, 11, 11],\n",
    "    \"FP\": [4, 0, 0, 0],\n",
    "}\n",
    "\n",
    "df_combined_summary_4 = face_detection_summary(\n",
    "    name_list=detectors_4[\"name\"],\n",
    "    GT_list=detectors_4[\"GT\"],\n",
    "    TP_list=detectors_4[\"TP\"],\n",
    "    FP_list=detectors_4[\"FP\"]\n",
    ")\n",
    "\n",
    "print(\"4_Dancing_Dancing_4_489\")\n",
    "print(df_combined_summary_2)\n",
    "print()\n",
    "print(\"30_Surgeons_Surgeons_30_256\")\n",
    "print(df_combined_summary_3)\n",
    "print()\n",
    "print(\"50_Celebration_Or_Party_houseparty_50_17\")\n",
    "print(df_combined_summary_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 - Porównanie wyników\n",
    "\n",
    "### Zdjęcie: 4_Dancing_Dancing_4_489\n",
    "Ludzie na scenie + 2 małe tłumy w tle\n",
    "\n",
    "1. InsightFace zdecydowanie przewyższa inne detektory, wykrywając prawie wszystkie twarze (37/39).\n",
    "\n",
    "1. Klasyczne detektory (Haar, HOG SVM, CNN MMOD) pomijają 13 twarzy – najpewniej osoby w tle lub słabo widoczne.\n",
    "\n",
    "1. HOG SVM i CNN MMOD nie popełniły żadnych fałszywych detekcji (FP=0), co tłumaczy 100% precision, ale kosztem recall.\n",
    "\n",
    "1. InsightFace łączy bardzo wysoki recall z minimalną liczbą FP – idealne dla analizy zdjęć tłumu.\n",
    "\n",
    "### Zdjęcie: 30_Surgeons_Surgeons_30_256\n",
    "5 chirurgów z maseczkami, zasłonięte twarze\n",
    "\n",
    "1. Klasyczne detektory kompletnie zawiodły – nie wykryto żadnej twarzy.\n",
    "\n",
    "1. Przyczyną są zasłonięte twarze, brak widocznych ust, nosa, szczęki.\n",
    "\n",
    "1. Tylko InsightFace poradził sobie z tym trudnym przypadkiem – wykrył 3/5 twarzy, mimo że widoczne były praktycznie tylko oczy i czoło.\n",
    "\n",
    "1. To dowód na większą odporność InsightFace na nietypowe ujęcia i przesłony.\n",
    "\n",
    "\n",
    "### Zdjęcie: 50_Celebration_Or_Party_houseparty_50_17\n",
    "11 czarnoskórych osób, dobre ustawienie, ale nierówne oświetlenie\n",
    "\n",
    "1. CNN MMOD i InsightFace spisały się perfekcyjnie – wykryły wszystkie twarze bez błędów.\n",
    "\n",
    "1. HOG SVM wykrył tylko 6 z 11 twarzy, ale nie popełnił fałszywych detekcji.\n",
    "\n",
    "1. Haar znowu ma najniższą skuteczność – jego model może mieć trudności z różnorodnością oświetlenia i odcieni skóry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Haar  HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)     159.00   159.00    159.00       159.00\n",
      "Total Detections       65.00    53.00     64.00       108.00\n",
      "True Positives (TP)    53.00    53.00     64.00       107.00\n",
      "False Negatives (FN)  106.00   106.00     95.00        52.00\n",
      "False Positives (FP)   12.00     0.00      0.00         1.00\n",
      "Precision               0.82     1.00      1.00         0.99\n",
      "Recall                  0.33     0.33      0.40         0.67\n",
      "F1-score                0.47     0.50      0.57         0.80\n",
      "Miss Rate               0.67     0.67      0.60         0.33\n"
     ]
    }
   ],
   "source": [
    "name_list = [\"Haar\", \"HOG SVM\", \"CNN MMOD\", \"InsightFace\"]\n",
    "GT_total = [x + y + z + w for x, y, z, w in zip(detectors_1[\"GT\"], detectors_2[\"GT\"], detectors_3[\"GT\"], detectors_4[\"GT\"])]\n",
    "TP_total = [x + y + z + w for x, y, z, w in zip(detectors_1[\"TP\"], detectors_2[\"TP\"], detectors_3[\"TP\"], detectors_4[\"TP\"])]\n",
    "FP_total = [x + y + z + w for x, y, z, w in zip(detectors_1[\"FP\"], detectors_2[\"FP\"], detectors_3[\"FP\"], detectors_4[\"FP\"])]\n",
    "\n",
    "df_combined_summary_all = face_detection_summary(name_list, GT_total, TP_total, FP_total)\n",
    "print(df_combined_summary_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 - Porównanie wyników\n",
    "\n",
    "### InsightFace\n",
    "1. Zdecydowanie najlepsze ogólne wyniki:\n",
    "\n",
    "1. Najwyższy recall (0.67) — wykrywa 2× więcej twarzy niż Haar/HOG\n",
    "\n",
    "1. Bardzo wysoka precision (0.99) — prawie wszystkie wykrycia to trafne twarze\n",
    "\n",
    "1. F1-score = 0.80 — zbalansowana, silna skuteczność\n",
    "\n",
    "1. Tylko 1 fałszywa detekcja na 108 prób\n",
    "\n",
    "### CNN MMOD\n",
    "1. Zero fałszywych trafień (precision = 1.00), ale recall znacznie niższy (0.40)\n",
    "\n",
    "1. Nie popełnia błędnych wykryć, ale pomija aż 95 twarzy — zbyt ostrożny\n",
    "\n",
    "### HOG SVM\n",
    "1. Zero fałszywych trafień (precision = 1.00), ale bardzo niski recall (0.33)\n",
    "\n",
    "1. Skuteczność (F1-score = 0.50) mocno ograniczona przez liczbę pominiętych twarzy\n",
    "\n",
    "### Haar\n",
    "Najsłabsze wyniki:\n",
    "\n",
    "1. Najniższy F1-score (0.47) i najwyższa liczba fałszywych wykryć (12)\n",
    "\n",
    "1. Średnia precyzja (0.82), a i tak nie znajduje 2/3 twarzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 - Wnioski\n",
    "\n",
    "1. InsightFace wyraźnie dominuje pod względem ogólnej skuteczności, nawet w scenach trudnych – takich jak twarze w maseczkach, ciemne karnacje, tłumy w tle czy nierówne oświetlenie.\n",
    "Uzyskuje najlepszy balans między precyzją a czułością, a liczba fałszywych wykryć jest niemal zerowa.\n",
    "\n",
    "1. Haar cascade to najstarszy i najmniej skuteczny z testowanych detektorów. Choć działa szybko, cechuje się niską czułością (Recall) i największą liczbą fałszywych detekcji (FP) spośród wszystkich metod. Może być przydatny jedynie w bardzo prostych warunkach i tam, gdzie liczy się tylko szybkość.\n",
    "\n",
    "1. HOG + SVM wypada nieco lepiej niż Haar – nie generuje fałszywych wykryć, ale pomija większość twarzy, zwłaszcza w złożonych scenach. Jego zaletą jest stabilność i brak błędnych alarmów, ale skuteczność ogólna pozostaje niska.\n",
    "\n",
    "1. CNN MMOD jest kompromisem – osiąga wysoką precyzję (zero fałszywych detekcji), jednak jego czułość nadal jest niższa niż w przypadku InsightFace. Nie wykrywa wszystkich twarzy, ale działa zdecydowanie lepiej niż klasyczne metody."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hog_svm0=6\n",
      "hog_svm1=21\n",
      "hog_svm2=29\n",
      "cnn0=4\n",
      "cnn1=27\n",
      "cnn2=37\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: insightface\\models\\buffalo_s\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (512, 512)\n",
      "insightface0.5=41\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: insightface\\models\\buffalo_s\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (1024, 1024)\n",
      "insightface1=56\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: insightface\\models\\buffalo_s\\det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (2048, 2048)\n",
      "insightface2=64\n"
     ]
    }
   ],
   "source": [
    "parameters = [0, 1, 2]\n",
    "\n",
    "\n",
    "hog_svm_detector = dlib.get_frontal_face_detector()\n",
    "for parameter in parameters:\n",
    "    hog_svm_results = hog_svm_detector(images_rgb[0], parameter)\n",
    "    print(f\"hog_svm{parameter}=\" + str(len(hog_svm_results)))\n",
    "\n",
    "    img_hog_svm = images_rgb[0].copy()\n",
    "    for rect in hog_svm_results:\n",
    "        cv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_hog_svm))\n",
    "    save_result(img_hog_svm, f\"zad4_HOG_SVM_parameter_{parameter}\")\n",
    "\n",
    "\n",
    "cnn1_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
    "for parameter in parameters:\n",
    "    cnn1_results = cnn1_detector(images_rgb[0], parameter)\n",
    "    print(f\"cnn{parameter}=\" + str(len(cnn1_results)))\n",
    "\n",
    "    img_cnn1 = images_rgb[0].copy()\n",
    "    for res in cnn1_results:\n",
    "        rect = res.rect\n",
    "        cv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_cnn1))\n",
    "    save_result(img_cnn1, f\"zad4_CNN_parameter_{parameter}\")\n",
    "\n",
    "\n",
    "for parameter in [0.5, 1, 2]:\n",
    "    model_name = 'buffalo_s'  # model: small (_s), medium (_m) lub large (_l)\n",
    "    insf_detector = insightface.app.FaceAnalysis(name=model_name, root='insightface',\n",
    "                                             allowed_modules=['detection'], providers=['CPUExecutionProvider'])\n",
    "    insf_detector.prepare(ctx_id=0, det_size=(int(1024*parameter), int(1024*parameter)))\n",
    "    insf_results = insf_detector.get(images[0])\n",
    "    print(f\"insightface{parameter}=\" + str(len(insf_results)))\n",
    "\n",
    "    img_insf = images_rgb[0].copy()\n",
    "    for res in insf_results:\n",
    "        rect = res.bbox.round().astype(int)\n",
    "        cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "    # display(Image.fromarray(img_insf))\n",
    "    save_result(img_insf, f\"zad4_InsightFace_parameter{parameter}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4 - Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectors Paramater: 0, 0, (512, 512)\n",
      "                      HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)      104.00    104.00       104.00\n",
      "Total Detections         6.00      4.00        40.00\n",
      "True Positives (TP)      6.00      4.00        40.00\n",
      "False Negatives (FN)    98.00    100.00        64.00\n",
      "False Positives (FP)     0.00      0.00         0.00\n",
      "Precision                1.00      1.00         1.00\n",
      "Recall                   0.06      0.04         0.38\n",
      "F1-score                 0.11      0.07         0.56\n",
      "Miss Rate                0.94      0.96         0.62\n",
      "\n",
      "Detectors Paramater: 1, 1, (1024, 1024)\n",
      "                      HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)      104.00    104.00       104.00\n",
      "Total Detections        21.00     27.00        56.00\n",
      "True Positives (TP)     21.00     27.00        56.00\n",
      "False Negatives (FN)    83.00     77.00        48.00\n",
      "False Positives (FP)     0.00      0.00         0.00\n",
      "Precision                1.00      1.00         1.00\n",
      "Recall                   0.20      0.26         0.54\n",
      "F1-score                 0.34      0.41         0.70\n",
      "Miss Rate                0.80      0.74         0.46\n",
      "\n",
      "Detectors Paramater: 2, 2, (2048, 2048)\n",
      "                      HOG SVM  CNN MMOD  InsightFace\n",
      "Ground Truth (GT)      104.00    104.00       104.00\n",
      "Total Detections        29.00     37.00        64.00\n",
      "True Positives (TP)     29.00     37.00        63.00\n",
      "False Negatives (FN)    75.00     67.00        41.00\n",
      "False Positives (FP)     0.00      0.00         1.00\n",
      "Precision                1.00      1.00         0.98\n",
      "Recall                   0.28      0.36         0.61\n",
      "F1-score                 0.44      0.52         0.75\n",
      "Miss Rate                0.72      0.64         0.39\n"
     ]
    }
   ],
   "source": [
    "# Detectors Paramater: 0, 0, (512, 512)\n",
    "detectors_0 = {\n",
    "    \"name\": [\"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [104, 104, 104], # reference 101\n",
    "    \"TP\": [6, 4, 40],\n",
    "    \"FP\": [0, 0, 0, 1],\n",
    "}\n",
    "\n",
    "df_combined_summary_0 = face_detection_summary(\n",
    "    name_list=detectors_0[\"name\"],\n",
    "    GT_list=detectors_0[\"GT\"],\n",
    "    TP_list=detectors_0[\"TP\"],\n",
    "    FP_list=detectors_0[\"FP\"]\n",
    ")\n",
    "\n",
    "# Detectors Paramater: 1, 1, (1024, 1024)\n",
    "detectors_1 = {\n",
    "    \"name\": [\"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [104, 104, 104], # reference 101\n",
    "    \"TP\": [21, 27, 56],\n",
    "    \"FP\": [0, 0, 0],\n",
    "}\n",
    "\n",
    "df_combined_summary_1 = face_detection_summary(\n",
    "    name_list=detectors_1[\"name\"],\n",
    "    GT_list=detectors_1[\"GT\"],\n",
    "    TP_list=detectors_1[\"TP\"],\n",
    "    FP_list=detectors_1[\"FP\"]\n",
    ")\n",
    "\n",
    "# Detectors Paramater: 2, 2, (2048, 2048)\n",
    "detectors_2 = {\n",
    "    \"name\": [\"HOG SVM\", \"CNN MMOD\", \"InsightFace\"],\n",
    "    \"GT\": [104, 104, 104], # reference 101\n",
    "    \"TP\": [29, 37, 63],\n",
    "    \"FP\": [0, 0, 1],\n",
    "}\n",
    "\n",
    "df_combined_summary_2 = face_detection_summary(\n",
    "    name_list=detectors_2[\"name\"],\n",
    "    GT_list=detectors_2[\"GT\"],\n",
    "    TP_list=detectors_2[\"TP\"],\n",
    "    FP_list=detectors_2[\"FP\"]\n",
    ")\n",
    "\n",
    "print(\"Detectors Paramater: 0, 0, (512, 512)\")\n",
    "print(df_combined_summary_0)\n",
    "print()\n",
    "print(\"Detectors Paramater: 1, 1, (1024, 1024)\")\n",
    "print(df_combined_summary_1)\n",
    "print()\n",
    "print(\"Detectors Paramater: 2, 2, (2048, 2048)\")\n",
    "print(df_combined_summary_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4 - Porównanie i wnioski\n",
    "\n",
    "### HOG SVM:\n",
    "1. Skalowanie obrazu silnie wpływa na skuteczność: recall rośnie z 0.06 do 0.28, co oznacza 5-krotny wzrost liczby wykrytych twarzy.\n",
    "\n",
    "1. Precision pozostaje 1.00 (brak błędnych detekcji), ale pomijanych jest wiele twarzy przy niskim przeskalowaniu.\n",
    "\n",
    "1. Detektor jest wyraźnie niewrażliwy na małe twarze, widzi je dopiero po kilkukrotnym przeskalowaniu.\n",
    "\n",
    "### CNN MMOD:\n",
    "1. Podobna zależność jak w HOG — więcej małych twarzy znajduje się przy wyższym skalowaniu.\n",
    "\n",
    "1. Wyniki są ogólnie lepsze niż HOG (Recall 0.36 vs 0.28 przy skali 2), ale też bardziej czasochłonne.\n",
    "\n",
    "1. Skuteczność (F1-score) poprawia się ponad 7× między skalą 0 a 2.\n",
    "\n",
    "### InsightFace:\n",
    "1. Już przy skali 0.5 (512×512) osiąga lepsze wyniki niż HOG SVM i CNN MMOD przy skali 2.\n",
    "\n",
    "1. Najlepsze wyniki osiąga przy 2048×2048 (Recall 0.61, F1-score 0.75).\n",
    "\n",
    "1. Mniej zachowawaczy od innych detektorów. Miał 1 fałszywą detekcję w całym eksperymencie.\n",
    "\n",
    "1. Przy wyższym skalowaniu znajduje coraz to bardziej rozmyte twarze. Jednakże rozmyte obiekty może również kwalifikwoać jako twarze."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
